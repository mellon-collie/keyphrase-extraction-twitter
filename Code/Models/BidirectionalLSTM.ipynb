{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uVQmtjSrvVfY"},"outputs":[],"source":["import _pickle as cPickle\n","f = open('data_set2.pkl','rb')\n","train_set, test_set, dicts = cPickle.load(f,encoding='utf-8')\n","\n","train_lex, train_y, train_z = train_set\n","test_lex,  test_y, test_z  = test_set\n","\n","MAX_LENGTH = len(max(train_lex, key=len))\n","\n","\n","from keras.preprocessing.sequence import pad_sequences\n","train_sentences_X = pad_sequences(train_lex,maxlen=MAX_LENGTH,padding='post')\n","train_tags_y = pad_sequences(train_y,maxlen=MAX_LENGTH,padding='post')\n","\n","test_sentences_X = pad_sequences(test_lex,maxlen=MAX_LENGTH,padding='post')\n","test_tags_y = pad_sequences(test_y,maxlen=MAX_LENGTH,padding='post')\n","\n","train_tags_z = pad_sequences(train_z,maxlen=MAX_LENGTH,padding='post')\n","test_tags_z = pad_sequences(test_z,maxlen=MAX_LENGTH,padding='post')\n","\n","\n","import numpy as np\n","def to_categorical(sequences,categories):\n","    cat_sequences = []\n","    for s in sequences:\n","        cats = []\n","        for item in s:\n","            cats.append([item])\n","        cat_sequences.append(cats)\n","    return np.array(cat_sequences)\n","\n","def to_categorical2(sequences, categories):\n","    cat_sequences = []\n","    for s in sequences:\n","        cats = []\n","        for item in s:\n","            cats.append(np.zeros(categories))\n","            cats[-1][item] = 1.0\n","        cat_sequences.append(cats)\n","    return np.array(cat_sequences)\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, Dropout, Input\n","from keras.optimizers import Adam\n","\n","from keras import backend as K\n"," \n","def ignore_class_accuracy(to_ignore=0):\n","    def ignore_accuracy(y_true, y_pred):\n","        y_true_class = K.argmax(y_true, axis=-1)\n","        y_pred_class = K.argmax(y_pred, axis=-1)\n","        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'float32')\n","        matches = K.cast(K.equal(y_true_class, y_pred_class), 'float32') * ignore_mask\n","        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n","        return accuracy\n","    return ignore_accuracy\n","\n","\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.models import Model\n","\n","inputLayer = Input(shape=(MAX_LENGTH,),dtype='float32')\n","embedding = Embedding(len(dicts['words2idx'].keys())+1,128,mask_zero=True)(inputLayer)\n","hiddenLayer1 = Bidirectional(LSTM(128,return_sequences=True))(embedding)\n","dropoutLayer = Dropout(0.5)(hiddenLayer1)\n","hiddenLayer2 = Bidirectional(LSTM(128,return_sequences=True))(dropoutLayer)\n","keyphraseDenseLayer = TimeDistributed(Dense(6,activation='softmax'),name='keyphrase')(hiddenLayer2)\n","model1 = Model(inputLayer, keyphraseDenseLayer)\n","\n","\n","model1 = Model(inputLayer, keyphraseDenseLayer)\n","\n","model1.compile(loss = 'categorical_crossentropy',\n","             optimizer = Adam(0.01),\n","             metrics = ['accuracy',ignore_class_accuracy(0)])\n","\n","f = model1.fit(train_sentences_X,to_categorical2(train_tags_z,6),batch_size=128,epochs=1,validation_split=0.2,shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IBmJGKqvVfc"},"outputs":[],"source":["scores = model1.evaluate(test_sentences_X, to_categorical2(test_tags_z, 6))\n","print(scores)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"BidirectionalLSTM.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}